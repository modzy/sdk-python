{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes on executing the demo:\n",
    "\n",
    "1. Make sure to port forward the service from the integration cluster: `kubectl port-forward svc/model-converter -n modzy 8080:8080`\n",
    "2. Set envionrment variables: `MODZY_QA_API_KEY`, `SP_ACCESS_KEY_ID` and `SP_SECRET_ACCESS_KEY`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First we will convert an Explainable SageMaker Image Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import some standard dependencies\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Train a built-in model on the SageMaker Platform\n",
    "\n",
    "The raw output of the SageMaker Platform will be a set of weights for your image classification model that is stored within a bucket on AWS S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob_storage_provider = \"S3\"\n",
    "blob_storage_container = \"modzy-engineering-tests\"\n",
    "sagemaker_weights_key = \"ds/model-converter/sagemaker/image-classification/weights.tar.gz\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Provide metadata specific to your model\n",
    "\n",
    "You are encouraged to fill out a `model.yaml` file describing your model and provide any additional metadata files for the specific model type that you chose. In the case of image classification, you will need to provide a `labels.json` file that contains a mapping between numerical classes and human readable labels. For example, 12 could be the label for a \"tabby cat\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modzy.converter.utils import upload_resources\n",
    "\n",
    "current_working_directory = os.getcwd()\n",
    "\n",
    "# Indicate where your local files\n",
    "model_yaml_path = os.path.join(current_working_directory, \"examples/sagemaker/image-classification/model.yaml\")\n",
    "labels_json_path = os.path.join(current_working_directory, \"examples/sagemaker/image-classification/labels.json\")\n",
    "auxiliary_files = [labels_json_path]\n",
    "\n",
    "# Your local files will be archieved and stored in the following location:\n",
    "sagemaker_resources_key = \"ds/demo/model-converter/sagemaker/image-classification/resources.tar.gz\"\n",
    "\n",
    "\n",
    "upload_resources(\n",
    "    model_yaml_path, blob_storage_container, sagemaker_resources_key,\n",
    "    os.getenv(\"SP_ACCESS_KEY_ID\"), os.getenv(\"SP_SECRET_ACCESS_KEY\"), blob_storage_provider, auxiliary_files\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Use the Modzy Python SDK to set up an API Client to the Model Converter Service\n",
    "\n",
    "The Modzy Python SDK has a number of convenience functions that we will use to:\n",
    "* connect to our instance of modzy\n",
    "* interact with the model converter service\n",
    "* manage processing engines for our new model\n",
    "* run jobs against our new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from modzy.converter.model_converter import ModelConverter\n",
    "from modzy.client import ApiClient\n",
    "\n",
    "# To get started, store your Modzy API key as an environment variable `MODZY_API_KEY`.\n",
    "# Then, create a Modzy API client to interact with the integration envrionment\n",
    "modzy_api_key = os.getenv(\"MODZY_QA_API_KEY\")\n",
    "modzy_instance_base_url = \"https://integration.modzy.engineering/api\"\n",
    "modzy_api_client = ApiClient(api_key=modzy_api_key, base_url=modzy_instance_base_url)\n",
    "\n",
    "# Instantiate a Model Converter client with access to the Modzy integration environment\n",
    "model_converter = ModelConverter(modzy_api_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model details page for your new model can be found here: https://integration.modzy.engineering/models/c59e25fe2a/0.0.1\n"
     ]
    }
   ],
   "source": [
    "# Now, provide the Model converter with information about your stored model assets and the credentials required\n",
    "# to access them. The Model converter will do the rest of the work.\n",
    "\n",
    "source_platform = \"sagemaker\"\n",
    "model_type = \"image-classification\"\n",
    "\n",
    "_, sagemaker_converter_output = model_converter.run(\n",
    "    sp_access_key_id=os.getenv(\"SP_ACCESS_KEY_ID\"),\n",
    "    sp_secret_access_key=os.getenv(\"SP_SECRET_ACCESS_KEY\"),\n",
    "    blobstore_provider=blob_storage_provider,\n",
    "    blobstore_container=blob_storage_container,\n",
    "    weights_path=sagemaker_weights_key,\n",
    "    resources_path=sagemaker_resources_key,\n",
    "    platform=source_platform,\n",
    "    model_type=model_type,\n",
    ")\n",
    "\n",
    "print(f\"The model details page for your new model can be found here: {sagemaker_converter_output['modelURL']}\")\n",
    "sagemaker_model_id = sagemaker_converter_output[\"modelId\"]\n",
    "sagemaker_model_version = sagemaker_converter_output[\"modelVersion\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warming up a container to perform inference from model c59e25fe2a version 0.0.1\n"
     ]
    }
   ],
   "source": [
    "# Delegate a single processing engine to serve your new model\n",
    "modzy_api_client.models.update_processing_engines(\n",
    "    sagemaker_model_id, sagemaker_model_version, min_engines=1, max_engines=1\n",
    ")\n",
    "print(\n",
    "    f\"Warming up a container to perform inference from model {sagemaker_model_id} version {sagemaker_model_version}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending job to model c59e25fe2a version 0.0.1\n",
      "Job Completed: https://integration.modzy.engineering/operations/jobs/1b4f7fe0-8a42-4cd7-8557-5e57bc3a3913\n"
     ]
    }
   ],
   "source": [
    "# Send an inference job to run against your new model with explainability!\n",
    "sagemaker_input_source = {\n",
    "    \"00001\": {\n",
    "        f\"image\": {\n",
    "            \"bucket\": blob_storage_container,\n",
    "            \"key\": f\"/ds/model-converter/{source_platform}/{model_type}/test_input\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "print(f\"Sending job to model {sagemaker_model_id} version {sagemaker_model_version}\")\n",
    "job = modzy_api_client.jobs.submit_aws_s3_bulk(\n",
    "    sagemaker_model_id, sagemaker_model_version, sagemaker_input_source,\n",
    "    os.getenv(\"SP_ACCESS_KEY_ID\"), os.getenv(\"SP_SECRET_ACCESS_KEY\"),\n",
    "    region=\"us-east-1\", explain=True\n",
    ")\n",
    "\n",
    "modzy_api_client.jobs.block_until_complete(job, timeout=None)\n",
    "print(f\"Job Completed: https://integration.modzy.engineering/operations/jobs/{job.job_identifier}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Release the processing engine\n",
    "modzy_api_client.models.update_processing_engines(\n",
    "    sagemaker_model_id, sagemaker_model_version, min_engines=0, max_engines=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next, we will convert an MLflow model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modzy.converter.mlflow import upload_mlflow_model\n",
    "\n",
    "# TODO: add training code\n",
    "\n",
    "# Now we repeat the process with an MLFlow model\n",
    "source_platform = \"mlflow\"\n",
    "model_type = \"tabular\"\n",
    "\n",
    "mlflow_model_dir = os.path.join(current_working_directory, \"examples/mlflow/tabular/weights\")\n",
    "mlflow_weights_key = \"demo/mlflow-wine/weights.tar.gz\"\n",
    "\n",
    "upload_mlflow_model(\n",
    "   mlflow_model_dir, blob_storage_container, mlflow_weights_key,\n",
    "   os.getenv(\"SP_ACCESS_KEY_ID\"), os.getenv(\"SP_SECRET_ACCESS_KEY\"), blob_storage_provider\n",
    ")\n",
    "\n",
    "mlflow_model_yaml_path = os.path.join(current_working_directory, \"examples/mlflow/tabular/model.yaml\")\n",
    "mlflow_resources_key = \"ds/demo/model-converter/mlflow/tabular/resources.tar.gz\"\n",
    "\n",
    "upload_resources(\n",
    "    mlflow_model_yaml_path, blob_storage_container, mlflow_resources_key,\n",
    "    os.getenv(\"SP_ACCESS_KEY_ID\"), os.getenv(\"SP_SECRET_ACCESS_KEY\"), blob_storage_provider, auxiliary_files\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model details page for your new model can be found here: https://integration.modzy.engineering/models/eab49768ff/0.1.0\n"
     ]
    }
   ],
   "source": [
    "_, mlflow_converter_output = model_converter.run(\n",
    "    sp_access_key_id=os.getenv(\"SP_ACCESS_KEY_ID\"),\n",
    "    sp_secret_access_key=os.getenv(\"SP_SECRET_ACCESS_KEY\"),\n",
    "    blobstore_provider=blob_storage_provider,\n",
    "    blobstore_container=blob_storage_container,\n",
    "    weights_path=mlflow_weights_key,\n",
    "    resources_path=mlflow_resources_key,\n",
    "    platform=source_platform,\n",
    "    model_type=model_type,\n",
    ")\n",
    "\n",
    "print(f\"The model details page for your new model can be found here: {mlflow_converter_output['modelURL']}\")\n",
    "mlflow_model_id = mlflow_converter_output[\"modelId\"]\n",
    "mlflow_model_version = mlflow_converter_output[\"modelVersion\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Delegate a single processing to serve your new model\n",
    "modzy_api_client.models.update_processing_engines(mlflow_model_id, mlflow_model_version, min_engines=1, max_engines=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending job to model eab49768ff 0.1.0\n",
      "Job Completed: https://integration.modzy.engineering/operations/jobs/90490dfa-d80b-494e-8b47-26d0bbaeb806\n"
     ]
    }
   ],
   "source": [
    "# Send an inference job to run against your new model!\n",
    "input_source = {\n",
    "    \"0001\": {\n",
    "        f\"input.csv\": {\n",
    "            \"bucket\": blob_storage_container,\n",
    "            \"key\": f\"/ds/model-converter/{source_platform}/{model_type}/test_input\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "print(f\"Sending job to model {mlflow_model_id} {mlflow_model_version}\")\n",
    "job = modzy_api_client.jobs.submit_aws_s3_bulk(\n",
    "    mlflow_model_id, mlflow_model_version, input_source,\n",
    "    os.getenv(\"SP_ACCESS_KEY_ID\"), os.getenv(\"SP_SECRET_ACCESS_KEY\"),\n",
    "    region=\"us-east-1\"\n",
    ")\n",
    "\n",
    "modzy_api_client.jobs.block_until_complete(job, timeout=None)\n",
    "print(f\"Job Completed: https://integration.modzy.engineering/operations/jobs/{job.job_identifier}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spin down the resources when down performing inference\n",
    "modzy_api_client.models.update_processing_engines(mlflow_model_id, mlflow_model_version, min_engines=0, max_engines=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}